{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Thanks to :** [spaCy vs NLTK - Which is the better Choice for NLP?](https://konfuzio.com/en/spacy-vs-nltk/)"
      ],
      "metadata": {
        "id": "aChgxaT5N4NX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is spaCy?\n",
        "- **spaCy** is an open source library for the Python programming language.\n",
        "- It was developed by <U>*Matthew Honnibal and Ines Montani*</u>, the founders of the software company [explosion.ai](https://explosion.ai/), for *natural language processing* **(NLP).**\n",
        "- **spaCy** uses techniques such as\n",
        "  - tokenization,\n",
        "  - part-of-speech (POS)\n",
        "  - tagging and\n",
        "  - lemmatization<br>\n",
        "\n",
        " to analyse texts."
      ],
      "metadata": {
        "id": "PywM7U_KgcQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is NLTK?\n",
        "The **Natural Language Toolkit (NLTK)** is a collection of libraries and programs for the Python programming language. It was originally developed by <u>*Steven Bird, Ewan Klein and Edward Loper*</u> for applications in computational linguistics. Like spaCy, it provides the basic functions for NLP. NLTK is open source and is distributed under the Apache license."
      ],
      "metadata": {
        "id": "MPEn9VMugxiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Difference between spaCy and NLTK\n",
        "* **spaCy** is like a service that **developers use to solve specific problems.** The library is therefore particularly *suitable for production environments.*\n",
        "* **NLTK** is like a *large toolbox with which developers can choose from many different solutions for a problem.* The library is therefore aimed particularly at **scientists.**"
      ],
      "metadata": {
        "id": "ZywrFMVz66_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Functionality and features\n",
        "### spaCy:\n",
        "- **spaCy** is structured like a service.\n",
        "- This means that it provides a *precise solution for every problem.*\n",
        "- In practice, this means that developers can complete specific *tasks quickly and easily with **spaCy**.*\n",
        "- In addition to the basic NLP functions, *the library has various extensions and visualization tools* such as **displaCy or displaCyENT.**\n",
        "- It also contains *pre-trained models* for various languages.\n",
        "- In total, **spaCy** supports more than **60 languages,** including **German, English, Spanish, Portuguese, Italian, French, Dutch and Greek.**\n",
        "\n",
        "### NLTK:\n",
        "- **NLTK** is a large toolbox of NLP algorithms.\n",
        "- In practice, this means that *developers can choose from a variety of solutions to a problem and test them out.*\n",
        "- In addition to the **classic NLP functions,** the library offers access to a *large number of corpora and resources for NLP research.*\n",
        "- In total, **NLTK** supports over **20 languages,** including **German, English, French, Spanish, Portuguese, Italian, Greek and Dutch.**"
      ],
      "metadata": {
        "id": "P4gRVQnBhfBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Performance and speed\n",
        "### spaCy:\n",
        "- **spaCy** is known for its *high speed and efficiency.*\n",
        "- The developers **Honnibal and Montani** have optimized the library to quickly process large amounts of text data.\n",
        "\n",
        "### NLTK:\n",
        "- **NLTK** offers a solid performance, but tends to be [slower than spaCy](https://medium.com/nerd-for-tech/natural-language-processing-text-preprocessing-spacy-vs-nltk-b70b734f5560#), *especially when processing large amounts of text.*"
      ],
      "metadata": {
        "id": "nrrSj7SihqhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Ease of use\n",
        "### spaCy:\n",
        "- Developers praise spaCy for its user-friendliness.\n",
        "- It offers an intuitive API and well-documented functions that make it easy even for beginners to quickly work productively with the library.\n",
        "\n",
        "### NLTK:\n",
        "- **NLTK** is significantly more comprehensive than spaCy.\n",
        "- The *variety of functions available* can therefore be overwhelming for beginners.\n",
        "- In addition, the library often requires more code to perform certain NLP tasks, which makes it more challenging for beginners."
      ],
      "metadata": {
        "id": "uirmBa0Thyu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Community support\n",
        "### spaCy:\n",
        "- **spaCy** has a constantly growing and committed community of developers and researchers.\n",
        "- There is an active mailing list, online forums and social media where users can ask questions.\n",
        "- The community also develops and shares external extensions and plugins.\n",
        "- Particularly popular points of contact for developers include the [GitHub Forum](https://github.com/explosion/spaCy/discussions), [Stack Overflow for spaCy](https://stackoverflow.com/questions/tagged/spacy) and the [spaCy Github Repository](https://github.com/explosion/spaCy).\n",
        "\n",
        "### NLTK:\n",
        "- **NLTK** has been an established library for a long time and therefore also has a large and diverse community.\n",
        "- There are numerous resources such as tutorials, books and online discussion forums created by experienced members of the community.\n",
        "- Popular places to go, for example, are the [NLTK Google Group](https://groups.google.com/g/nltk-users?pli=1) and the [NLTK GitHub Repository](https://github.com/nltk/nltk)."
      ],
      "metadata": {
        "id": "CGwD5JUvh-II"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Customization options\n",
        "### spaCy:\n",
        "- **spaCy** allows developers to train custom models for NLP tasks such as *Named Entity Recognition* (**NER**) and provides tools for fine-tuning existing models.\n",
        "- This flexibility makes **spaCy** particularly suitable for projects that need to recognize specific entities or terminology.\n",
        "\n",
        "### NLTK:\n",
        "- **NLTK** offers a wide range of algorithms and tools that allow developers to create customized NLP applications.\n",
        "- It enables the training of models for various tasks such as **classification and sentiment analysis.**\n",
        "- With its modular structure, NLTK allows in-depth customization and implementation of specific algorithms for advanced research projects."
      ],
      "metadata": {
        "id": "a9kxJVkgi8We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion: spaCy vs NLTK - Result\n",
        "### spaCy\n",
        "* Developers use **spaCy** to implement functions efficiently.\n",
        "* The library is therefore less of a tool and more of a service.\n",
        "* It is particularly suitable for production environments such as app development.\n",
        "\n",
        "### NLTK\n",
        "* **NLTK**, on the other hand, allows developers to choose from a wide range of algorithms for a problem and easily extend the library modules.\n",
        "* **NLTK** thus enables developers to work as flexibly as possible.\n",
        "* The library is therefore primarily aimed at scientists and researchers who want to develop models from scratch."
      ],
      "metadata": {
        "id": "r57ttmbyjMGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# Load the spaCy model for the English language\n",
        "nlp_spacy = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "RM2OSHirOI_1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text to be tokenized\n",
        "text = \"SpaCy is a powerful Python library for natural language processing.\"\n",
        "\n",
        "# Process the text using spaCy\n",
        "spacy_tokenize = nlp_spacy(text)\n",
        "\n",
        "# Tokenize the text and print each token\n",
        "for word in spacy_tokenize:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuTQcHHMOV4p",
        "outputId": "e25d9794-63d0-41f3-8a21-6635c9966f06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy\n",
            "is\n",
            "a\n",
            "powerful\n",
            "Python\n",
            "library\n",
            "for\n",
            "natural\n",
            "language\n",
            "processing\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "MqvA00tUO-ZH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the nltk model for the English language\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiUdPXLtPnJn",
        "outputId": "2237eb92-82d7-4e76-cdfa-5bfc491366b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text to be tokenized\n",
        "text = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
        "\n",
        "# Process the text using nltk\n",
        "nltk_tokenize = word_tokenize(text)\n",
        "\n",
        "# Print the token\n",
        "print(nltk_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRfCXKJRPFQY",
        "outputId": "4869aafa-57e2-4991-8f37-91817c2ebad8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spaCy:\n",
        "* **Focus:** Industrial-strength NLP library designed for production use.\n",
        "* **Speed:** Highly optimized and fast.\n",
        "* **Ease of use:** User-friendly API with built-in support for modern NLP tasks.\n",
        "* **Features:** Pre-trained models for\n",
        " * various languages,\n",
        " * named entity recognition,\n",
        " * part-of-speech tagging,\n",
        " * dependency parsing,\n",
        " * lemmatization, and more.\n",
        "\n",
        "## NLTK:\n",
        "* **Focus:** Educational and research-oriented NLP library.\n",
        "* **Speed:** Slower compared to spaCy.\n",
        "* **Ease of use:** Comprehensive but can be more complex to use.\n",
        "* **Features:** Extensive set of tools for text processing, including *\n",
        " * tokenization,\n",
        " * stemming,\n",
        " * tagging,\n",
        " * parsing, and\n",
        " * corpora for linguistic data."
      ],
      "metadata": {
        "id": "fZ4sxjQVFj4e"
      }
    }
  ]
}