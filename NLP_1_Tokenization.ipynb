{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "\n",
        "## 1.1 Definition\n",
        "\n",
        "**Natural Language Processing (NLP)** is a field of artificial intelligence that focuses on the interaction between computers and human language. It involves the development of algorithms and techniques that enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
        "\n",
        "## 1.2 Tokenization\n",
        "\n",
        "* **Tokenization** in natural language processing (NLP) refers to the process of *breaking down a text into smaller units, typically words or sentences.* These smaller units are called **tokens.**\n",
        "\n",
        "* **Tokenization** is a fundamental step in most NLP tasks because it helps to prepare the text data for further processing and analysis.\n",
        "\n",
        "  There are two main types of tokenization:\n",
        "\n",
        "* **1. Word Tokenization:** This involves splitting the text into individual words.\n",
        "\n",
        "  For example, the sentence **\"The quick brown fox jumps over the lazy dog\"** *would be tokenized into* <br>\n",
        "  `[\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"].`\n"
      ],
      "metadata": {
        "id": "77xpJNbnv65R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **2. Sentence Tokenization:** This involves splitting the text into individual sentences.\n",
        "\n",
        "  For example, the paragraph **\"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet\"** *would be tokenized into*\n",
        "\n",
        "  `[\"NLTK is a leading platform for building Python programs to work with human language data.\",`\n",
        "\n",
        "  `\"It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet.\"]`.\n",
        "\n",
        "**Tokenization** can be more complex in languages with **punctuation marks, contractions, or other linguistic nuances,** but the goal remains the same: ***to segment the text into meaningful units for further analysis.***"
      ],
      "metadata": {
        "id": "ajUTfLGVzzDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Different types of tokenization library\n",
        "\n",
        "There are several libraries and tools available for tokenization in various programming languages. Here are some popular ones:\n",
        "\n",
        "1. **NLTK (Natural Language Toolkit): NLTK** provides robust tokenization functionality for Python. It offers both **word** and **sentence** tokenization along with various other NLP tools.\n",
        "\n",
        "2. **spaCy: spaCy** is a modern NLP library for Python that offers efficient tokenization along with other NLP capabilities such as\n",
        "\n",
        " * part-of-speech tagging,\n",
        " * named entity recognition, and\n",
        " * dependency parsing.\n",
        "\n",
        "3. **Stanford CoreNLP: Stanford CoreNLP** is a suite of NLP tools that includes tokenization among other functionalities. It supports tokenization for multiple languages and can be used via Python wrappers or directly through Java.\n",
        "\n",
        "4. **Gensim: Gensim** is a Python library primarily used for topic modeling and document similarity analysis. It also provides tokenization capabilities for processing text data.\n",
        "\n",
        "5. **Scikit-learn:** While primarily a machine learning library, scikit-learn includes **tokenization** functionality as part of its text preprocessing utilities.\n"
      ],
      "metadata": {
        "id": "9okbvSgu1IGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **TensorFlow Text:** TensorFlow Text is a library for text-based deep learning tasks within TensorFlow. It includes **tokenization** functions optimized for TensorFlow workflows.\n",
        "\n",
        "7. **Hugging Face Transformers:** This library provides state-of-the-art pre-trained models for natural language understanding and generation. It often includes **tokenizers** specific to the models it provides.\n",
        "\n",
        "8. **Apache OpenNLP:** OpenNLP is a Java library for **NLP** tasks. It includes **tokenization** among other functionalities.\n",
        "\n",
        "9. **TextBlob Word Tokenize:** TextBlob is a Python library for processing textual data. It provides a consistent API for diving into common natural language processing (**NLP**) tasks such as\n",
        " * part-of-speech tagging,\n",
        " * noun phrase extraction,\n",
        " * sentiment analysis,\n",
        " * classification,\n",
        " * translation, and more.\n",
        "\n",
        "## 1.4 How to install **TextBlob** and the **NLTK** corpora:\n",
        "```\n",
        "$pip install -U textblob\n",
        "$python3 -m textblob.download_corpora\n",
        "```\n",
        "These are just a few examples, and there are many more **tokenization** libraries available, each with its own strengths and focus areas. The choice of library often depends on factors such as programming language preference, performance requirements, and specific NLP tasks being tackled.\n"
      ],
      "metadata": {
        "id": "X7iOqukl2CIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 [Punkt Tokenizer Models](https://www.nltk.org/api/nltk.tokenize.punkt.html)\n",
        "* For pre-trained English **tokenization** in NLTK, the best data package to use is the **\"Punkt Tokenizer Models\"**.\n",
        "* The Punkt tokenizer is a sentence tokenizer included in NLTK that is pre-trained on English text. It's widely used and generally performs well for various English text processing tasks.\n",
        "\n",
        "To use the **Punkt tokenizer,** you need to download the appropriate NLTK data package:\n",
        "```\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "```"
      ],
      "metadata": {
        "id": "dxb8l7AO5LFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import libraries"
      ],
      "metadata": {
        "id": "rBg8Zbt32J1m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LJQ8WccE_HN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae6ce4e-ae9d-4a16-aa56-2b90871ae823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# import the necessary libraries required for tokenization.\n",
        "import nltk\n",
        "# nltk.download('all')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load dataset"
      ],
      "metadata": {
        "id": "FVpKf4ip2-AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset for tokenization.\n",
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds.\n",
        "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours.\n",
        "               Yet we have not done this to any other nation. We have not conquered anyone.\n",
        "               We have not grabbed their land, their culture,\n",
        "               their history and tried to enforce our way of life on them.\n",
        "               Why? Because we respect the freedom of others.That is why my\n",
        "               first vision is that of freedom. I believe that India got its first vision of\n",
        "               this in 1857, when we started the War of Independence. It is this freedom that\n",
        "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
        "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
        "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
        "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
        "               I have a third vision. India must stand up to the world. Because I believe that unless India\n",
        "               stands up to the world, no one will respect us. Only strength respects strength. We must be\n",
        "               strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
        "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of\n",
        "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
        "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.\n",
        "               I see four milestones in my career\"\"\""
      ],
      "metadata": {
        "id": "pDsuZxUv9q95"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Processing\n",
        "## 4.1 Converting paragraphs into sentences"
      ],
      "metadata": {
        "id": "Baj8S3GD-K5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "sentences                                                   # entire paraagraph\n",
        "print(\"List of sentences\".ljust(50,'.'), sentences)         # list of sentences in an entire paragraph\n",
        "print(\"Number of sentences\".ljust(50,'.'), len(sentences))  # number of sentences in an entire paragraph in numeric (integer)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1SOlKo294ij",
        "outputId": "023d1c23-e258-4c38-9228-65a85df911ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of sentences................................. ['I have three visions for India.', 'In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds.', 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours.', 'Yet we have not done this to any other nation.', 'We have not conquered anyone.', 'We have not grabbed their land, their culture,\\n               their history and tried to enforce our way of life on them.', 'Why?', 'Because we respect the freedom of others.That is why my\\n               first vision is that of freedom.', 'I believe that India got its first vision of\\n               this in 1857, when we started the War of Independence.', 'It is this freedom that\\n               we must protect and nurture and build on.', 'If we are not free, no one will respect us.', 'My second vision for India’s development.', 'For fifty years we have been a developing nation.', 'It is time we see ourselves as a developed nation.', 'We are among the top 5 nations of the world\\n               in terms of GDP.', 'We have a 10 percent growth rate in most areas.', 'Our poverty levels are falling.', 'Our achievements are being globally recognised today.', 'Yet we lack the self-confidence to\\n               see ourselves as a developed nation, self-reliant and self-assured.', 'Isn’t this incorrect?', 'I have a third vision.', 'India must stand up to the world.', 'Because I believe that unless India\\n               stands up to the world, no one will respect us.', 'Only strength respects strength.', 'We must be\\n               strong not only as a military power but also as an economic power.', 'Both must go hand-in-hand.', 'My good fortune was to have worked with three great minds.', 'Dr. Vikram Sarabhai of the Dept.', 'of\\n               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.', 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.', 'I see four milestones in my career']\n",
            "Number of sentences............................... 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Converting sentences into words"
      ],
      "metadata": {
        "id": "nTZxwQm0-Tjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# words = nltk.word_tokenize(sentences) # sentences is a \"list\" of word statement, so showing an error\n",
        "words = nltk.word_tokenize(paragraph)                       # entire paraagraph\n",
        "words\n",
        "print(\"List of words\".ljust(50,'.'), words)                 # list of words in an entire paragraph\n",
        "print(\"Number of words\".ljust(50,'.'), len(words))          # number of words in an entire paragraph in numeric (integer)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFcIHHv8-Z44",
        "outputId": "21094d5c-707c-4481-9ca5-963ad954671d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of words..................................... ['I', 'have', 'three', 'visions', 'for', 'India', '.', 'In', '3000', 'years', 'of', 'our', 'history', ',', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us', ',', 'captured', 'our', 'lands', ',', 'conquered', 'our', 'minds', '.', 'From', 'Alexander', 'onwards', ',', 'the', 'Greeks', ',', 'the', 'Turks', ',', 'the', 'Moguls', ',', 'the', 'Portuguese', ',', 'the', 'British', ',', 'the', 'French', ',', 'the', 'Dutch', ',', 'all', 'of', 'them', 'came', 'and', 'looted', 'us', ',', 'took', 'over', 'what', 'was', 'ours', '.', 'Yet', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation', '.', 'We', 'have', 'not', 'conquered', 'anyone', '.', 'We', 'have', 'not', 'grabbed', 'their', 'land', ',', 'their', 'culture', ',', 'their', 'history', 'and', 'tried', 'to', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them', '.', 'Why', '?', 'Because', 'we', 'respect', 'the', 'freedom', 'of', 'others.That', 'is', 'why', 'my', 'first', 'vision', 'is', 'that', 'of', 'freedom', '.', 'I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', '1857', ',', 'when', 'we', 'started', 'the', 'War', 'of', 'Independence', '.', 'It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on', '.', 'If', 'we', 'are', 'not', 'free', ',', 'no', 'one', 'will', 'respect', 'us', '.', 'My', 'second', 'vision', 'for', 'India', '’', 's', 'development', '.', 'For', 'fifty', 'years', 'we', 'have', 'been', 'a', 'developing', 'nation', '.', 'It', 'is', 'time', 'we', 'see', 'ourselves', 'as', 'a', 'developed', 'nation', '.', 'We', 'are', 'among', 'the', 'top', '5', 'nations', 'of', 'the', 'world', 'in', 'terms', 'of', 'GDP', '.', 'We', 'have', 'a', '10', 'percent', 'growth', 'rate', 'in', 'most', 'areas', '.', 'Our', 'poverty', 'levels', 'are', 'falling', '.', 'Our', 'achievements', 'are', 'being', 'globally', 'recognised', 'today', '.', 'Yet', 'we', 'lack', 'the', 'self-confidence', 'to', 'see', 'ourselves', 'as', 'a', 'developed', 'nation', ',', 'self-reliant', 'and', 'self-assured', '.', 'Isn', '’', 't', 'this', 'incorrect', '?', 'I', 'have', 'a', 'third', 'vision', '.', 'India', 'must', 'stand', 'up', 'to', 'the', 'world', '.', 'Because', 'I', 'believe', 'that', 'unless', 'India', 'stands', 'up', 'to', 'the', 'world', ',', 'no', 'one', 'will', 'respect', 'us', '.', 'Only', 'strength', 'respects', 'strength', '.', 'We', 'must', 'be', 'strong', 'not', 'only', 'as', 'a', 'military', 'power', 'but', 'also', 'as', 'an', 'economic', 'power', '.', 'Both', 'must', 'go', 'hand-in-hand', '.', 'My', 'good', 'fortune', 'was', 'to', 'have', 'worked', 'with', 'three', 'great', 'minds', '.', 'Dr.', 'Vikram', 'Sarabhai', 'of', 'the', 'Dept', '.', 'of', 'space', ',', 'Professor', 'Satish', 'Dhawan', ',', 'who', 'succeeded', 'him', 'and', 'Dr.', 'Brahm', 'Prakash', ',', 'father', 'of', 'nuclear', 'material', '.', 'I', 'was', 'lucky', 'to', 'have', 'worked', 'with', 'all', 'three', 'of', 'them', 'closely', 'and', 'consider', 'this', 'the', 'great', 'opportunity', 'of', 'my', 'life', '.', 'I', 'see', 'four', 'milestones', 'in', 'my', 'career']\n",
            "Number of words................................... 399\n"
          ]
        }
      ]
    }
  ]
}