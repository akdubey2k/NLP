{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To compare the **execution timing and performance** of **NLTK and spaCy,** you can use the *built-in* **time**  module in Python."
      ],
      "metadata": {
        "id": "8gdQQz4FqP3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il4x4ndxp9O0",
        "outputId": "def132b2-3a7f-4d6b-b4b8-9317f509afa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.155001\n",
            "2.093861\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "# NLTK example\n",
        "nltk_start = time.time()\n",
        "nltk.download('punkt')\n",
        "nltk_end = time.time()\n",
        "nltk_time = nltk_end - nltk_start\n",
        "print(f\"{nltk_time:.6f}\")\n",
        "\n",
        "# spaCy example\n",
        "spacy_start = time.time()\n",
        "spacy.load('en_core_web_sm')\n",
        "spacy_end = time.time()\n",
        "spacy_time = spacy_end - spacy_start\n",
        "print(f\"{spacy_time:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK Example\n",
        "nltk_start = time.time()\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "nltk_end = time.time()\n",
        "nltk_time = nltk_end - nltk_start\n",
        "print(f\"NLTK Tokenization Time : {nltk_time:.6f} seconds.\")\n",
        "\n",
        "# spaCy Example\n",
        "spacy_start = time.time()\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "doc = spacy_nlp(sentence)\n",
        "spacy_end = time.time()\n",
        "spacy_time = spacy_end - spacy_start\n",
        "print(f\"spaCy Tokenization Time : {nltk_time:.6f} seconds.\")\n",
        "\n",
        "# Compare the execution times\n",
        "print(f\"\\nNLTK is {nltk_time/spacy_time:.6f} times slower than spaCy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6j73BFarGA0",
        "outputId": "b308cc8f-5231-47c6-e847-b228065dbaa3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokenization Time : 0.020876 seconds.\n",
            "spaCy Tokenization Time : 0.020876 seconds.\n",
            "\n",
            "NLTK is 0.024739 times slower than spaCy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare the timing of execution for performance metrics between **NLTK** and **spaCy,** you can use Python's **`time`** module or **`timeit`** module.\n",
        "<br>Below are examples for both methods: using time for a simple timing comparison and timeit for more precise measurements.\n",
        "\n",
        "# Method 1: Using `time` Module\n",
        "The **`time`** module provides a simple way to measure the elapsed time for small code snippets.\n",
        "\n",
        "## Tokenization"
      ],
      "metadata": {
        "id": "d9h3Moy51IvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "\n",
        "# Text for processing\n",
        "text = \"SpaCy is an amazing NLP library.\"\n",
        "\n",
        "# NLTK Timing\n",
        "start_time = time.time()\n",
        "nltk.download('punkt')\n",
        "nltk_tokens = word_tokenize(text)\n",
        "nltk_time = time.time() - start_time\n",
        "print(f\"NLTK Tokenization Time: {nltk_time:.6f} seconds\")\n",
        "\n",
        "# spaCy Timing\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "start_time = time.time()\n",
        "doc = nlp(text)\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "spacy_time = time.time() - start_time\n",
        "print(f\"spaCy Tokenization Time: {spacy_time:.6f} seconds\")\n",
        "\n",
        "# Compare the execution times\n",
        "print(f\"\\nNLTK is {nltk_time/spacy_time:.6f} times slower than spaCy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-bq6mGz12bp",
        "outputId": "bd0d5558-c50b-41ec-a9b1-34b5c8537731"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokenization Time: 0.000662 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Tokenization Time: 0.008684 seconds\n",
            "\n",
            "NLTK is 0.076245 times slower than spaCy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2: Using timeit Module\n",
        "The **`timeit`** module is more accurate for measuring the execution time of small code snippets.\n",
        "\n",
        "## Tokenization"
      ],
      "metadata": {
        "id": "BZhikW0p7DVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "\n",
        "# Text for processing\n",
        "text = \"SpaCy is an amazing NLP library.\"\n",
        "\n",
        "# NLTK Timing\n",
        "nltk_setup = \"\"\"\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "text = \"SpaCy is an amazing NLP library.\"\n",
        "\"\"\"\n",
        "nltk_code = \"word_tokenize(text)\"\n",
        "nltk_time = timeit.timeit(stmt=nltk_code, setup=nltk_setup, number=1000)\n",
        "print(f\"NLTK Tokenization Time (1000 runs): {nltk_time:.6f} seconds\")\n",
        "\n",
        "# spaCy Timing\n",
        "spacy_setup = \"\"\"\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"SpaCy is an amazing NLP library.\"\n",
        "\"\"\"\n",
        "spacy_code = \"nlp(text)\"\n",
        "spacy_time = timeit.timeit(stmt=spacy_code, setup=spacy_setup, number=1000)\n",
        "print(f\"spaCy Tokenization Time (1000 runs): {spacy_time:.6f} seconds\")\n",
        "\n",
        "# Compare the execution times\n",
        "print(f\"\\nNLTK is {nltk_time/spacy_time:.6f} times slower than spaCy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RPO-5dU7T1n",
        "outputId": "60b28c3d-7636-43c6-ba80-76d5b9dd320e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Tokenization Time (1000 runs): 0.101097 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Tokenization Time (1000 runs): 8.741541 seconds\n",
            "\n",
            "NLTK is 0.011565 times slower than spaCy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-Of_Speech Tagging"
      ],
      "metadata": {
        "id": "YlsX8Tk59Xcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "\n",
        "# Text for processing\n",
        "text = \"SpaCy is an amazing NLP library.\"\n",
        "\n",
        "# NLTK Timing\n",
        "nltk_setup = \"\"\"\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "text = \"SpaCy is an amazing NLP library.\"\n",
        "tokens = word_tokenize(text)\n",
        "\"\"\"\n",
        "nltk_code = \"nltk.pos_tag(tokens)\"\n",
        "nltk_time = timeit.timeit(stmt=nltk_code, setup=nltk_setup, number=1000)\n",
        "print(f\"NLTK POS Tagging Time (1000 runs): {nltk_time:.6f} seconds\")\n",
        "\n",
        "# spaCy Timing\n",
        "spacy_setup = \"\"\"\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"SpaCy is an amazing NLP library.\"\n",
        "\"\"\"\n",
        "spacy_code = \"\"\"\n",
        "doc = nlp(text)\n",
        "[(token.text, token.pos_) for token in doc]\n",
        "\"\"\"\n",
        "spacy_time = timeit.timeit(stmt=spacy_code, setup=spacy_setup, number=1000)\n",
        "print(f\"spaCy POS Tagging Time (1000 runs): {spacy_time:.6f} seconds\")\n",
        "\n",
        "# Compare the execution times\n",
        "print(f\"\\nNLTK is {nltk_time/spacy_time:.6f} times slower than spaCy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeFfKC9T9bN9",
        "outputId": "f380fd1e-c8fc-4188-9f72-11cabb223882"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK POS Tagging Time (1000 runs): 0.617091 seconds\n",
            "spaCy POS Tagging Time (1000 runs): 7.435949 seconds\n",
            "\n",
            "NLTK is 0.082988 times slower than spaCy.\n"
          ]
        }
      ]
    }
  ]
}