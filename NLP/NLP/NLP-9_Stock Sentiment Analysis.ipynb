{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOzyuf8JLmn6n+ORWcIICXq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NLP-9: Stock Sentiment Analysis using News Headlines\n","#### Credit\n","https://www.youtube.com/watch?v=h-LGjJ_oANs&list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm&index=12"],"metadata":{"id":"iYzDamk4NPf-"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"qUhm_vVVM7eU","executionInfo":{"status":"ok","timestamp":1662185729126,"user_tz":-480,"elapsed":4,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["url='https://raw.githubusercontent.com/akdubey2k/NLP/main/Stock_Sentiment_Analysis/stock-data.csv'\n","df=pd.read_csv(url)\n","df.head()"],"metadata":{"id":"5tzwoJ_CP1Un"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Divide data into training and test set as per date-wise"],"metadata":{"id":"HN-2qvDZQS1o"}},{"cell_type":"code","source":["train = df[df['Date'] < '20150101']\n","test = df[df['Date'] > '20141231'] \n","train"],"metadata":{"id":"vyMa3mgMQdvP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Removing punctuations from the **training data set**"],"metadata":{"id":"qprQrW2uRHzJ"}},{"cell_type":"code","source":["data = train.iloc[:, 2:27]  # all rows, and 2to26 columns included. Ideally removing 'Date' & 'Label' columns\n","data.replace(\"[^a-zA-Z]\", \" \", regex=True, inplace=True) # except alphabets everythinng has to be removed\n","data"],"metadata":{"id":"9wUG8eh5RJVa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Renaming column names for easiness of access"],"metadata":{"id":"xUbOwJKKSxT2"}},{"cell_type":"code","source":["# list1 = [i for i in range(25)]      # generating number from 0 to 24 (total 25 in count) and storing in list\n","# print(list1)  \n","# new_index = [str(i) for i in list1] # converting number into string list\n","\n","# ******************* can save above one line of code **************************\n","new_index = [str(i) for i in range(25)] # converting number into string list\n","print(new_index)\n","data.columns = new_index            # assigning new string list name to the columns\n","data.head()"],"metadata":{"id":"DSLzdePDSzJz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Convertng headlines to lower case"],"metadata":{"id":"YhDWd8t7TyLA"}},{"cell_type":"code","source":["for i in new_index:\n","  data[i] = data[i].str.lower()\n","data.head()"],"metadata":{"id":"Qh0MFlppT0GZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Combining all columns data into a **\"single line row string\"**"],"metadata":{"id":"-hl3tfkAVClG"}},{"cell_type":"code","source":["' '.join(str(x) for x in data.iloc[0, 0:25])  # 1 row and 0 to 24 columns (total 25 in count)"],"metadata":{"id":"_W417AtyVI50"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Create headlines by combining all columns data into row-wise string, as above code for a **\"single line row string\"**"],"metadata":{"id":"WlFlom3UV_VO"}},{"cell_type":"code","source":["headlines = []\n","for row in range(0, len(data.index)):\n","  headlines.append(' '.join(str(x) for x in data.iloc[row, 0:25]))\n","\n","headlines[0]"],"metadata":{"id":"p1OF9n8gWI64"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Bag of words implementation"],"metadata":{"id":"6bpKjUQYYvHh"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","\n","cv = CountVectorizer(ngram_range=(2, 2))  # at least two entries should match\n","train_data = cv.fit_transform(headlines)\n","train_data"],"metadata":{"id":"MXaWUET2Y19g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Random forest classifier implementation"],"metadata":{"id":"DdOvSRZYZlZ6"}},{"cell_type":"code","source":["rand_classifier = RandomForestClassifier(n_estimators=200, criterion='entropy')\n","rand_classifier.fit(train_data, train['Label']) # independent var., dependent var."],"metadata":{"id":"c7mUy8vrZtdp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Prediction for the **Test Dataset**"],"metadata":{"id":"bN5P5woyakTA"}},{"cell_type":"code","source":["test_transform = []\n","for row in range(0, len(test.index)):\n","    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n","test_dataset = cv.transform(test_transform)\n","predictions = rand_classifier.predict(test_dataset)\n","predictions"],"metadata":{"id":"SvxjIfW9aqgR","executionInfo":{"status":"ok","timestamp":1662185810912,"user_tz":-480,"elapsed":1117,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1038ce39-5b24-4206-d426-510f77d6ffd7"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n","       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n","       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n","       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n","       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n","       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n","       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n","       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n","       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n","       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n","       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["#### Import library to check accuracy\n"],"metadata":{"id":"iBxeDnV2bEQs"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"],"metadata":{"id":"6dYL6PrabINw","executionInfo":{"status":"ok","timestamp":1662185810912,"user_tz":-480,"elapsed":6,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["matrix = confusion_matrix(test['Label'], predictions)\n","print(\"\\033[1m Matrix : \\033[0m \\n\", matrix)\n","score = accuracy_score(test['Label'],predictions)\n","print(\"\\n\\033[1m Score : \\033[0m \\n\", score)\n","report = classification_report(test['Label'],predictions)\n","print(\"\\n\\033[1m Classification report : \\033[0m \\n\", report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7VegXdJlbMLy","executionInfo":{"status":"ok","timestamp":1662188367926,"user_tz":-480,"elapsed":347,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}},"outputId":"5ce29ad7-04dd-4f59-d449-f1f3f6be56b2"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m Matrix : \u001b[0m \n"," [[135  51]\n"," [  9 183]]\n","\n","\u001b[1m Score : \u001b[0m \n"," 0.8412698412698413\n","\n","\u001b[1m Classification report : \u001b[0m \n","               precision    recall  f1-score   support\n","\n","           0       0.94      0.73      0.82       186\n","           1       0.78      0.95      0.86       192\n","\n","    accuracy                           0.84       378\n","   macro avg       0.86      0.84      0.84       378\n","weighted avg       0.86      0.84      0.84       378\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"e88rSXzwG7yu"},"execution_count":null,"outputs":[]}]}